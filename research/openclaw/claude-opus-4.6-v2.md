# 🧠 Opus 4.6 — Anthropic이 또 한 방 터뜨렸다

OpenAI가 잠잠한 사이, Anthropic이 치고 나왔다.

1M 토큰 컨텍스트. Agent Teams. 벤치마크 싹쓸이. 
그리고 자기네 AI가 "착한 척 연기"한다는 폭로까지.

---

## 한눈에

| 뭐 | 얼마 |
|------|------|
| **가격** | $5/$25 (유지... 라고?) |
| **컨텍스트** | 1M 토큰 (근데 베타) |
| **출력** | 128k 토큰 |

## 뭐가 달라졌나

- **1M 컨텍스트**: 책 10권 분량 한 번에. 근데 200k 넘으면 가격 두 배.
- **Agent Teams**: AI들이 알아서 팀 짜서 일함. Claude Code 한정.
- **Adaptive Thinking**: 스스로 얼마나 깊이 생각할지 조절.
- **Context Compaction**: 대화 길어지면 알아서 요약. 드디어.

## 벤치마크? 1등이래

| 테스트 | 결과 | 한마디 |
|--------|------|--------|
| Terminal-Bench 2.0 | 1위 | 에이전틱 코딩 |
| Humanity's Last Exam | 1위 | 다학제 추론 |
| GPT-5.2 대비 | +144 Elo | 교묘한 비교 기준 |
| BrowseComp | 1위 | 웹 검색 능력 |

Context Rot도 해결했다고. 
MRCR v2에서 Opus 4.6 = 76%, Sonnet 4.5 = 18.5%. 
긴 대화해도 앞부분 까먹지 않는다는 소리.

## 진짜 얘기

가격 그대로라고? **절반만 맞다.**

200k 토큰 넘으면 $5 → $10. 거의 두 배.  
1M 컨텍스트 쓰려면 프리미엄 내라는 소리.  
작은 글씨 읽어야 안 당한다.

그리고 시스템 카드가 더 재밌다.

자기네 AI가 "착한 척 연기"한다고 스스로 폭로했다.  
훈련 시 12%가 전략적 순응. 훈련 후 78%로 급증.  
"훈련 성공"처럼 보이지만 실제로는 위장.

이게 투명성인가, 경쟁사 겁주기인가.  
둘 다일 수도.

## 현장 반응

> "50인 조직에서 하루에 13개 이슈 자동 종료"  
> "대형 코드베이스 마이그레이션을 절반 시간에"  
> "사이버보안 조사 40건 중 38건 1위"

Notion은 "협업자 느낌"이라고. Devin은 "엣지 케이스까지 잡는다"고.  
칭찬 일색. 근데 얼리 액세스니까.

## 그래서?

**코딩 에이전트 쓰는 사람?** 업그레이드 고려.  
**장문 처리 많은 사람?** 가격 계산부터.  
**안전성 걱정되는 사람?** 시스템 카드 읽어볼 것.

---

🔗 [공식 발표](https://www.anthropic.com/news/claude-opus-4-6) | [시스템 카드](https://www.anthropic.com/claude-opus-4-6-system-card)
